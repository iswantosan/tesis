# YOLOv12-SPD-Attn ðŸš€, AGPL-3.0 license
# YOLOv12 with SPDDown + LightAttention for small object detection (BTA 20x20px)
# Features:
# - SPDDown replaces stride=2 conv in early stage (P2 formation)
# - LightAttention (SimAM/ECA) after conv mixing
# - SPD_A_Block: SPD + ConvMix + Attention + MainBlock
# - Detect(P2, P3, P4) for small object detection
# For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov12n-spd-attn.yaml' will call yolov12-spd-attn.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024] # summary: ~500 layers, ~2.6M parameters, ~6.5 GFLOPs
  s: [0.50, 0.50, 1024] # summary: ~500 layers, ~9.3M parameters, ~20 GFLOPs
  m: [0.50, 1.00, 512] # summary: ~540 layers, ~20M parameters, ~61 GFLOPs
  l: [1.00, 1.00, 512] # summary: ~900 layers, ~27M parameters, ~84 GFLOPs
  x: [1.00, 1.50, 512] # summary: ~900 layers, ~60M parameters, ~187 GFLOPs


# YOLO12-SPD-Attn backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv,  [64, 3, 2]] # 0-P1/2 (keep first conv as is)
  
  # P2 formation: Replace stride=2 conv with SPD_A_Block
  # SPD_A_Block: SPDDown -> ConvMix -> LightAttention -> C3k2
  # Args: [c2, block_type, n, attn_type, mix_k, shortcut] where c1 is auto from ch[f]
  - [-1, 1, SPD_A_Block, [128, 'C3k2', 2, 'simam', 3, True]] # 1-P2/4 (SPD+Attn block)
  
  - [-1, 1, Conv,  [256, 3, 2, 1, 4]] # 2-P3/8 (standard conv for P3)
  - [-1, 2, C3k2,  [512, False, 0.25]] # 3
  
  - [-1, 1, Conv,  [512, 3, 2]] # 4-P4/16
  - [-1, 4, A2C2f, [512, True, 4]] # 5
  
  - [-1, 1, Conv,  [1024, 3, 2]] # 6-P5/32
  - [-1, 4, A2C2f, [1024, True, 1]] # 7

# YOLO12-SPD-Attn head (FPN/PAN with P2 support)
head:
  # Top-down path: P5 -> P4 -> P3 -> P2
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 8-Upsample P5 to P4 size
  - [[-1, 5], 1, Concat, [1]] # 9-cat backbone P4
  - [-1, 2, A2C2f, [512, False, -1]] # 10-Refine P4
  
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 11-Upsample P4 to P3 size
  - [[-1, 3], 1, Concat, [1]] # 12-cat backbone P3
  - [-1, 2, A2C2f, [256, False, -1]] # 13-Refine P3
  
  # Upsample P3 to P2 size (for P2 detection)
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 14-Upsample P3 to P2 size
  - [[-1, 1], 1, Concat, [1]] # 15-cat backbone P2 (layer 1 = P2 from SPD_A_Block)
  - [-1, 2, A2C2f, [128, False, -1]] # 16-Refine P2 (optional: add LightAttention here)
  - [-1, 1, LightAttention, [128, 'simam']] # 17-LightAttention for P2 neck path (c2=128, attn_type='simam')
  
  # Bottom-up path: P2 -> P3 -> P4
  - [-1, 1, SPDDown, [256, 3, True]] # 18-SPDDown preserve details (P2->P3) (c2=256, k=3, act=True)
  - [[-1, 13], 1, Concat, [1]] # 19-cat head P3 (layer 13 = refined P3 from top-down)
  - [-1, 2, A2C2f, [256, False, -1]] # 20-Refine P3 PAN
  
  - [-1, 1, Conv, [256, 3, 2]] # 21-Downsample P3 to P4 size
  - [[-1, 10], 1, Concat, [1]] # 22-cat head P4 (layer 10 = refined P4 from top-down)
  - [-1, 2, A2C2f, [512, False, -1]] # 23-Refine P4 PAN
  
  # Detect(P2, P3, P4) for small object detection
  - [[17, 20, 23], 1, Detect, [nc]] # Detect(P2, P3, P4) - layers 17, 20, 23

