# YOLOv12 ðŸš€, AGPL-3.0 license
# YOLOv12 object detection model with P2-P4 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
# CFG file for YOLOv12-turbo

# Parameters
nc: 1 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov12n.yaml' will call yolov12.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024] # summary: 497 layers, 2,553,904 parameters, 2,553,888 gradients, 6.2 GFLOPs
  s: [0.50, 0.50, 1024] # summary: 497 layers, 9,127,424 parameters, 9,127,408 gradients, 19.7 GFLOPs
  m: [0.50, 1.00, 512] # summary: 533 layers, 19,670,784 parameters, 19,670,768 gradients, 60.4 GFLOPs
  l: [1.00, 1.00, 512] # summary: 895 layers, 26,506,496 parameters, 26,506,480 gradients, 83.3 GFLOPs
  x: [1.00, 1.50, 512] # summary: 895 layers, 59,414,176 parameters, 59,414,160 gradients, 185.9 GFLOPs


# YOLO12-turbo backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv,  [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv,  [128, 3, 2, 1, 2]] # 1-P2/4
  - [-1, 2, C3k2,  [256, False, 0.25]]
  - [-1, 1, Conv,  [256, 3, 2, 1, 4]] # 3-P3/8
  - [-1, 2, C3k2,  [512, False, 0.25]]
  - [-1, 1, Conv,  [512, 3, 2]] # 5-P4/16
  - [-1, 4, A2C2f, [512, True, 4]]
  - [-1, 1, Conv,  [1024, 3, 2]] # 7-P5/32
  - [-1, 4, A2C2f, [1024, True, 1]] # 8
  - [-1, 1, SPPF, [1024, 5]] # 9 - Multi-scale features

# YOLO12-turbo head - Enhanced with RFB and MSFF for small object detection
head:
  # ===== TOP-DOWN =====
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]          # 10 P5->P4
  - [[-1, 6], 1, Concat, [1]]                           # 11 cat P4
  - [-1, 2, C2fRFB, [512, 0.5]]                         # 12 P4_td - RFB for multi-scale receptive field

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]          # 13 P4->P3
  - [[-1, 4], 1, Concat, [1]]                           # 14 cat P3
  - [-1, 2, C2fMSFF, [256, 0.5]]                        # 15 P3_td - MSFF for multi-scale fusion

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]          # 16 P3->P2
  - [[-1, 1], 1, Concat, [1]]                           # 17 cat P2
  - [-1, 2, A2C2f, [128, False, -1]]                    # 18 P2_td - Area attention for fine details

  # ===== P2 OUTPUT =====
  - [-1, 1, RFB, [128, 128]]                            # 19 - RFB for enhanced receptive field
  - [-1, 1, ChannelAttention, [128]]                    # 20
  - [-1, 1, SpatialAttention, [7]]                      # 21
  - [-1, 1, Conv, [128, 1, 1]]                          # 22 P2_out

  # ===== BOTTOM-UP P2 -> P3 =====
  - [-1, 1, Conv, [128, 3, 2]]                          # 23 downsample
  - [[-1, 15], 1, Concat, [1]]                          # 24 cat P3_td
  - [-1, 2, C2fMSFF, [256, 0.5]]                        # 25 - MSFF for multi-scale refinement
  - [-1, 1, ChannelAttention, [256]]                    # 26
  - [-1, 1, SpatialAttention, [7]]                      # 27
  - [-1, 1, Conv, [256, 1, 1]]                          # 28 P3_out

  # ===== BOTTOM-UP P3 -> P4 =====
  - [-1, 1, Conv, [256, 3, 2]]                          # 29 downsample
  - [[-1, 12], 1, Concat, [1]]                          # 30 cat P4_td
  - [-1, 2, C2fRFB, [512, 0.5]]                         # 31 - RFB for multi-scale features
  - [-1, 1, ChannelAttention, [512]]                    # 32
  - [-1, 1, SpatialAttention, [7]]                      # 33
  - [-1, 1, Conv, [512, 1, 1]]                          # 34 P4_out

  # ===== DETECT (SAFE RELATIVE INDEX) =====
  - [[-13, -7, -1], 1, Detect, [nc]]                    # Detect(P2,P3,P4)
